{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f30d691-f246-4673-a45e-b4b7e93e7624",
   "metadata": {},
   "source": [
    "# Data 695 Project Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823703eb-4152-4879-8837-f3b39f175b8f",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "Credit card fraud remains a major concern in the financial sector, causing substantial losses for both card issuers and consumers. \n",
    "Over $34 billion is lost annually to credit card fraud, a number that is expected to rise as digital transactions continue to grow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0b3b7-86a4-4371-b192-8ad1c8a15116",
   "metadata": {},
   "source": [
    "## Part 3 - Machine Learning Models with a Real-World Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483d749-d1ca-4bde-b08b-914302fa29d9",
   "metadata": {},
   "source": [
    "After evaluating logistic regression and support vector machine (SVM) models on a synthetic credit card fraud dataset, I will now apply the same models to a real-world dataset. \n",
    "\n",
    "The objective is to:\n",
    "1. Assess how the models perform on real-world transaction data,\n",
    "2. Compare model metrics such as precision, recall, F1 score, and accuracy,\n",
    "3. Evaluate whether performance improves or deteriorates compared to the synthetic dataset.\n",
    "\n",
    "This will help validate the robustness of our models and determine their practical applicability in realistic fraud detection scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f534df3-5017-403e-afc8-a2704d41b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    mean_squared_error,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    precision_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a5b36d-57c4-46cc-8b03-3593d112d88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.260648</td>\n",
       "      <td>-0.469648</td>\n",
       "      <td>2.496266</td>\n",
       "      <td>-0.083724</td>\n",
       "      <td>0.129681</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.519014</td>\n",
       "      <td>-0.130006</td>\n",
       "      <td>0.727159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110552</td>\n",
       "      <td>0.217606</td>\n",
       "      <td>-0.134794</td>\n",
       "      <td>0.165959</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>-0.434824</td>\n",
       "      <td>-0.081230</td>\n",
       "      <td>-0.151045</td>\n",
       "      <td>17982.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>-0.356045</td>\n",
       "      <td>0.558056</td>\n",
       "      <td>-0.429654</td>\n",
       "      <td>0.277140</td>\n",
       "      <td>0.428605</td>\n",
       "      <td>0.406466</td>\n",
       "      <td>-0.133118</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194936</td>\n",
       "      <td>-0.605761</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>0.190090</td>\n",
       "      <td>0.296503</td>\n",
       "      <td>-0.248052</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>6531.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.260272</td>\n",
       "      <td>-0.949385</td>\n",
       "      <td>1.728538</td>\n",
       "      <td>-0.457986</td>\n",
       "      <td>0.074062</td>\n",
       "      <td>1.419481</td>\n",
       "      <td>0.743511</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.261297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005020</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.945045</td>\n",
       "      <td>-1.154666</td>\n",
       "      <td>-0.605564</td>\n",
       "      <td>-0.312895</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.244718</td>\n",
       "      <td>2513.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.152152</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>1.746840</td>\n",
       "      <td>-1.090178</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>1.143312</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.065130</td>\n",
       "      <td>-0.205698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146927</td>\n",
       "      <td>-0.038212</td>\n",
       "      <td>-0.214048</td>\n",
       "      <td>-1.893131</td>\n",
       "      <td>1.003963</td>\n",
       "      <td>-0.515950</td>\n",
       "      <td>-0.165316</td>\n",
       "      <td>0.048424</td>\n",
       "      <td>5384.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.206820</td>\n",
       "      <td>-0.165280</td>\n",
       "      <td>1.527053</td>\n",
       "      <td>-0.448293</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>-0.212660</td>\n",
       "      <td>1.049921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106984</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>-0.161666</td>\n",
       "      <td>0.312561</td>\n",
       "      <td>-0.414116</td>\n",
       "      <td>1.071126</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.419117</td>\n",
       "      <td>14278.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0 -0.260648 -0.469648  2.496266 -0.083724  0.129681  0.732898  0.519014   \n",
       "1   1  0.985100 -0.356045  0.558056 -0.429654  0.277140  0.428605  0.406466   \n",
       "2   2 -0.260272 -0.949385  1.728538 -0.457986  0.074062  1.419481  0.743511   \n",
       "3   3 -0.152152 -0.508959  1.746840 -1.090178  0.249486  1.143312  0.518269   \n",
       "4   4 -0.206820 -0.165280  1.527053 -0.448293  0.106125  0.530549  0.658849   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0 -0.130006  0.727159  ... -0.110552  0.217606 -0.134794  0.165959  0.126280   \n",
       "1 -0.133118  0.347452  ... -0.194936 -0.605761  0.079469 -0.577395  0.190090   \n",
       "2 -0.095576 -0.261297  ... -0.005020  0.702906  0.945045 -1.154666 -0.605564   \n",
       "3 -0.065130 -0.205698  ... -0.146927 -0.038212 -0.214048 -1.893131  1.003963   \n",
       "4 -0.212660  1.049921  ... -0.106984  0.729727 -0.161666  0.312561 -0.414116   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  \n",
       "0 -0.434824 -0.081230 -0.151045  17982.10      0  \n",
       "1  0.296503 -0.248052 -0.064512   6531.37      0  \n",
       "2 -0.312895 -0.300258 -0.244718   2513.54      0  \n",
       "3 -0.515950 -0.165316  0.048424   5384.44      0  \n",
       "4  1.071126  0.023712  0.419117  14278.97      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Real-world Cleaned Credit card transaction data\n",
    "df = pd.read_csv('creditcard_2023.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de04adc9-96a6-4bd6-a5a6-35ed0a234ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568630, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3b02b-a5f2-4dec-99cd-b00a69f6ab2c",
   "metadata": {},
   "source": [
    "# Logistics Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d6da27-69af-49ef-98ca-a202a5dc9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the predictor variables (features)\n",
    "X = df.drop(columns=['Class'])  # 'Class' is the actual fraud indicator column\n",
    "\n",
    "# Defining the target variable\n",
    "y = df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9eafd8-30d3-46dd-b019-291842886997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Cross-validated F1 scores: [0.99850825 0.99817839 0.99844937]\n",
      "Logistic Regression - Mean F1 score: 0.9984\n",
      "Confusion Matrix:\n",
      "[[56811    52]\n",
      " [  137 56726]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop(columns=['Class'])  \n",
    "X = pd.get_dummies(X, drop_first=True)  \n",
    "y = df['Class'].astype(int)  \n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initializing and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear')\n",
    "\n",
    "# Cross-validation before model fitting\n",
    "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=3, scoring='f1')\n",
    "print(f\"Logistic Regression - Cross-validated F1 scores: {cv_scores}\")\n",
    "print(f\"Logistic Regression - Mean F1 score: {cv_scores.mean():.4f}\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707bab46-b058-41ad-addd-773580028014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9991\n",
      "Specificity: 0.9991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Ensuring the shape is valid \n",
    "if cm.shape == (2, 2):\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    # Computing precision and specificity \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "else:\n",
    "    print(\"Confusion matrix shape is not (2,2) — check if it's a binary classification problem.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df690561-2c44-4f90-930d-0658d0fb6201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9983\n",
      "F1 Score: 0.9983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Making sure predictions exist\n",
    "if 'y_pred' in locals():\n",
    "    # Computing Accuracy and F1 Score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "else:\n",
    "    print(\"Error: 'y_pred' is not defined. Please run model prediction first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0625822-0855-4972-b01b-97f1fb4bd9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculating Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30dc3cdb-0568-4231-8a2d-e6d18b17a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Recall: 0.9976\n",
      "Logistic Regression AUC-ROC: 0.9983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "# Recall \n",
    "logreg_recall = recall_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Recall: {logreg_recall:.4f}\")\n",
    "\n",
    "# AUC-ROC \n",
    "logreg_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression AUC-ROC: {logreg_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d9b3f13-3069-44be-b7d4-6e529c51b410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistics Regression Precision: 0.9991\n",
      "Logistics Regression Specificity: 0.9991\n",
      "Logistics Regression Accuracy: 0.9983\n",
      "Logistics Regression F1 Score: 0.9983\n",
      "Logistics Regression Mean Squared Error (MSE): 0.0017\n",
      "Logistic Regression Recall: 0.9976\n",
      "Logistic Regression AUC-ROC: 0.9983\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistics Regression Precision: {precision:.4f}\")\n",
    "print(f\"Logistics Regression Specificity: {specificity:.4f}\")\n",
    "print(f\"Logistics Regression Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Logistics Regression F1 Score: {f1:.4f}\")\n",
    "print(f\"Logistics Regression Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Logistic Regression Recall: {logreg_recall:.4f}\")\n",
    "print(f\"Logistic Regression AUC-ROC: {logreg_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0077e-cfda-43ef-97b4-9dceb79a1f37",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The Logistics Regression model had an overall accuracy of **0.9983,** and an F1-score of **0.9983** on the cleaned credit-card–fraud dataset, with an MSE of **0.0017.** \n",
    "\n",
    "The logistic regression model performed exceptionally well on the real-world credit card fraud dataset, achieving near-perfect precision and accuracy. This result indicates that the dataset is likely well-structured and separable, and that logistic regression can serve as a strong baseline model in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79550108-859d-47a1-b360-f283fcb2ddf7",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3fc39c-a1c4-4b0d-b56f-7a4ea4009e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Preparing X and y\n",
    "X = df.drop(columns=['Class'])  \n",
    "X = pd.get_dummies(X, drop_first=True)  \n",
    "y = df['Class'].astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train SVM with class_weight for imbalance\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale',\n",
    "    class_weight='balanced',  \n",
    "    random_state=42\n",
    ")\n",
    "svm_model.fit(X_train_s, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svm = svm_model.predict(X_test_s)\n",
    "\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_svm):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe1f5a-9b92-4310-b489-ef1ee549dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculating MSE\n",
    "mse = mean_squared_error(y_test, y_pred_svm)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c14913-6bf6-4a0a-94bf-9a2eacc41863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall \n",
    "svm_recall = recall_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Recall: {svm_recall:.4f}\")\n",
    "\n",
    "# AUC-ROC\n",
    "svm_auc = roc_auc_score(y_test, y_pred_svm)\n",
    "print(f\"SVM AUC-ROC: {svm_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95adcee-beff-42c6-a923-bb3eb5581ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_svm):.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"SVM Recall: {svm_recall:.4f}\")\n",
    "print(f\"SVM AUC-ROC: {svm_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2b94d-4f94-42dd-bb4b-13112a0d61f0",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The Support Vector Machine (SVM) model was applied to the cleaned and scaled credit card fraud dataset using an RBF kernel and class_weight='balanced' to address class imbalance. The model demonstrated strong performance, particularly in its ability to detect fraudulent transactions despite their rarity in the dataset.\n",
    "\n",
    "The SVM model offers a strong balance between precision and recall, making it a robust option for real-world fraud detection. Even though it's slightly more intensive to compute than logistic regression, its ability to detect complex fraud patterns gives it an edge in cases where linear models fall short. SVM can definitely serve as a reliable model for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d95bb0-99d4-4c95-886d-96f7cff34379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
